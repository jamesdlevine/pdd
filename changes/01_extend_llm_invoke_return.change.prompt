<pdd>
Target: pdd/llm_invoke.py

Prerequisites (run from ~/pdd):
  # Generate prompt from existing code if it doesn't exist
  pdd update pdd/llm_invoke.py --output prompts/llm_invoke_python.prompt

Apply change (run from ~/pdd):
  pdd change \
    ~/pdd_context_viz/changes/01_extend_llm_invoke_return.change.prompt \
    pdd/llm_invoke.py \
    prompts/llm_invoke_python.prompt \
    --output prompts/llm_invoke_python.prompt

Regenerate code:
  pdd generate llm_invoke --language python
</pdd>

Extend the return dictionary from `llm_invoke()` to include token counts and duration.

% Changes Required

1. Add these fields to the return dictionary at all return points:
   - `input_tokens`: from `_LAST_CALLBACK_DATA.get("input_tokens", 0)`
   - `output_tokens`: from `_LAST_CALLBACK_DATA.get("output_tokens", 0)`
   - `duration_ms`: calculated from existing `start_time` and `end_time` variables
   - `provider`: extracted from the model info or model name prefix

2. The existing return structure is:
   ```python
   return {
       'result': final_result,
       'cost': total_cost,
       'model_name': model_name_litellm,
       'thinking_output': final_thinking,
   }
   ```

3. The new return structure should be:
   ```python
   return {
       'result': final_result,
       'cost': total_cost,
       'model_name': model_name_litellm,
       'thinking_output': final_thinking,
       'input_tokens': _LAST_CALLBACK_DATA.get("input_tokens", 0),
       'output_tokens': _LAST_CALLBACK_DATA.get("output_tokens", 0),
       'duration_ms': int((end_time - start_time) * 1000),
       'provider': _extract_provider(model_name_litellm),
   }
   ```

4. Add a helper function to extract provider from model name:
   ```python
   def _extract_provider(model_name: str) -> str:
       """Extract provider name from model identifier."""
       if '/' in model_name:
           return model_name.split('/')[0]
       prefixes = ['claude', 'gpt', 'o1', 'o3', 'gemini', 'llama']
       for prefix in prefixes:
           if model_name.lower().startswith(prefix):
               if prefix in ['claude']:
                   return 'anthropic'
               if prefix in ['gpt', 'o1', 'o3']:
                   return 'openai'
               if prefix == 'gemini':
                   return 'google'
       return 'unknown'
   ```

% Backward Compatibility

This change is additive - existing code that reads `result`, `cost`, `model_name`, `thinking_output` will continue to work. New code can optionally access the additional fields.
