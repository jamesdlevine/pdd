<pdd>
Target: pdd/code_generator.py

Apply (from ~/pdd):
  pdd change ~/pdd_context_viz/changes/03_code_generator_instrumentation.change.prompt \
    pdd/code_generator.py prompts/code_generator_python.prompt \
    --output prompts/code_generator_python.prompt
</pdd>

% Context Map Feature - Code Generator Extended Return

Pass through the extended return fields from `llm_invoke` to callers.

% Current State

The `code_generator` function currently returns `Tuple[str, float, str]`:
- `runnable_code`: The generated code string
- `total_cost`: Cost of all LLM calls
- `model_name`: The model used

The `llm_invoke` function now returns additional fields: `input_tokens`, `output_tokens`, `duration_ms`, `provider`.

% Required Changes

Change the return type to a dictionary that includes both the original fields and new metrics:

```python
def code_generator(...) -> Dict[str, Any]:
    """
    Returns:
        Dictionary with keys:
        - 'runnable_code': str
        - 'total_cost': float
        - 'model_name': str
        - 'input_tokens': int (accumulated across calls)
        - 'output_tokens': int (accumulated across calls)
        - 'duration_ms': int (accumulated across calls)
        - 'provider': str
    """
```

% Implementation Notes

- Accumulate token counts across multiple LLM calls (initial generation + continuation if needed)
- Accumulate duration across all calls
- Provider comes from the first/main LLM call
- Default tokens to 0 if not available from response

% Backward Compatibility

Callers that currently unpack the tuple like `code, cost, model = code_generator(...)` will need updating. However, this is an internal function primarily called by `code_generator_main`, which is also being modified.

Alternatively, to maintain strict backward compatibility, add a `return_dict=False` parameter that controls the return format.
